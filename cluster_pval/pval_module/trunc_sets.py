"""Functions for computing truncation sets for test_hier_clusters_exact

Based on Lucy L Gao's trunc_sets.R script found here:
https://github.com/lucylgao/clusterpval/blob/master/R/trunc_sets.R
"""
import math

import numpy
import numpy as np
import scipy
import warnings


def compute_linear_ineq_complement(b, c, tol=1e-10):
    """ Computes the complement of the set {phi >= 0: b*phi + c >= 0}
    ignoring (-inf, 0]. Used for solving quadratic inequalities

    :param b: coefficient of the quadratic equation
    :param c: coefficient of the quadratic equation
    :param tol: tolerance for precision, how far from 0 a number can be and
    have us still consider it to be 0

    :return: np.array containing the complement set of
             {phi >= 0: b*phi + c >= 0} ignoring (-inf, 0]
    """
    # is b = 0?
    if np.isclose(abs(b), 0, atol=tol):
        if c >= -tol:
            # C >= -: inequality automatically satisfied
            return
        else:
            # C < 0: something has gone wrong
            warnings.warn("b = 0 and c < 0: b*phi + c >=0 is degenerate")
            return np.array([0,np.inf])

    # we know b != 0
    ratio = (-c) / b

    # is b > 0?
    if b > tol:
        if c >= -tol:
            # -c/b <= 0: inequality satisfied
            return
        else:
            # -c/b > 0: the interval extends to the right
            return np.array([0, ratio])

    # we know b < 0
    if c <= tol:
        # -c/b <= 0: inequality can't be satisfied
        return np.array([0, np.inf])

    # we know b < 0 and -c/b > 0: the interval extends to the left
    return np.array([ratio, np.inf])


def solve_one_ineq(a, b, c, tol=1e-10):
    """ Solves (ax^2 + bx + c) >= 0, returns the complement of the
    solution set wrt to the real line. If the complement is empty returns
    nan

    :param a: coefficient of the quadratic equation
    :param b: coefficient of the quadratic equation
    :param c: coefficient of the quadratic equation
    :param tol: tolerance for precision, how far from 0 a number can be and
    have us still consider it to be 0

    :return: np.array complement of the solution set (or containing nan if
    complement is empty)
    """

    # a = 0?
    if np.isclose(a, 0, atol=tol):
        return compute_linear_ineq_complement(b, c, tol)

    # we know a != 0
    discrim = (b^2) - (4*a*c)

    # no roots or one root?
    if discrim <= tol:
        if a > tol:
            # parabola opens up: inequality satisfied
            return
        else:
            # parabola opens down: inequality never satisfied
            return np.array([0, np.inf])

    # we now know that a != 0 and there are two roots
    sqrt_discrim = math.sqrt(discrim)
    roots = np.sort(np.array([-b + sqrt_discrim, -b - sqrt_discrim])/(2*a))
    print("roots = ".format(roots))

    # parabola opens up? (a > 0?)
    if a > tol:
        if roots[0] > tol:
            return np.array([roots[0], roots[1]])
        if roots[1] <= tol:
            return
        return(np.array([0, roots[1]]))

    # we now know there are two roots and parabola opens down (a < 0)
    if roots[1] < -tol:
        return np.array([0, np.inf])

    if roots[0] > tol:
        return np.array([0, roots[0], roots[1], np.inf])

    return np.array([roots[1], np.inf])

######################### Functions for computing Truncation Sets #############

def compute_s_single(x, hcl, k, k1, k2):
    pass

def compute_s_average(x, hcl, k, k1, k2):
    pass

def compute_s_centroid(x, hcl, k, k1, k2):
    pass

def compute_s_ward(x, hcl, k, k1, k2):
    pass

def compute_s_mcquitty(x, hcl, k, k1, k2):
    pass

def compute_s_median(x, hcl, k, k1, k2):
    pass

def compute_s_single_gencov(x, hcl, k, k1, k2, stat):
    pass

def compute_s_average_gencov(x, hcl, k, k1, k2, stat):
    pass

def compute_s_centroid_gencov(x, hcl, k, k1, k2, stat):
    pass

def compute_s_ward_gencov(x, hcl, k, k1, k2, stat):
    """ Computes conditioning set S for ward linkage hierarchical clustering
    without assuming isotropic covariance matrix

    This is a bit of a disaster but I'm initially trying to keep the
    structure consistent with the analagous R function. This should be
    refactored at some point.

    :param x: n by q matrix (np.array), containing numeric data
    :param hcl: clust object generated by
    sklearn.cluster.AgglomerativeClustering run with n_clusters=k,
    affinity='euclidean', linkage=ward, and then run hcl.fit_predict(x)
    :param k: the number of clusters
    :param k1: index of first cluster in test
    :param k2: index of second cluster in test
    :param stat: test statistic

    :return: conditioning set
    """

    # initialization and book-keeping
    rows, cols = x.shape
    n = rows

    #NOTE HEIGHTS HERE IS DIFFERENT THAN IN R
    heights = hcl.distances_

    #NOTE MERGES HERE IS DIFFERENT THAN IN R
    merges = hcl.children_

    cl = hcl.labels_
    k1_obs = np.where(cl == k1)
    k2_obs = np.where(cl == k2)
    other_obs = np.setdiff1d(np.arange(0, n-1, 1),
                             np.concatenate((k1_obs, k2_obs), axis=1))

    S_complement = np.array([-np.inf, 0])
    list_index = 1

    # where is each observation merged away?
    # if it is after the (n-K)th merge then that cluster still exists at step
    # (n-k)
    height_merge = np.repeat(n-k, n)
    for i in range(n):
        idx = np.argwhere(merges == i)
        height_merge[i] = idx[0][0]

    # Step 1
    cluster_sizes = np.repeat(1, n)
    merged_to_index = np.repeat(np.NaN, n)

    # Make the coefficients for d(i, i'; x'(phi))
    a = np.empty((n, n))
    a[:] = np.NaN
    b = np.copy(a)
    c = scipy.spatial.distance_matrix(x, x)
    c = c**2
    idx_to_nan = numpy.triu_indices(n, k=1)
    c[idx_to_nan] = np.NaN

    #compute quantities used in all coefficients
    prop_k2 = len(k2_obs[0])/(len(k1_obs[0]) + len(k2_obs[0]))
    squared_prop_k2 = prop_k2**2
    prop_k1 = prop_k2 - 1
    squared_prop_k1 = prop_k1**2
    k1colmeans = np.mean(x[cl == k1,:], axis=0)
    k2colmeans = np.mean(x[cl == k2,:], axis=0)
    diff_means = k1colmeans - k2colmeans
    squared_dist_means = sum(diff_means**2)
    dist_means = math.sqrt(squared_dist_means)
    gencov_factor = squared_dist_means/(stat**2)

    #compute coefficients involving i in cluster k1 and i' in cluster k2
    for i in k1_obs[0]:
        for j in k2_obs[0]:
            dif_ij = x[i,:] - x[j, :]
            cross_ij = sum(dif_ij*diff_means)

            if i > j:
                a[i, j] = gencov_factor
                b[i, j] = 2*(cross_ij - squared_dist_means)/stat
                c[i, j] = c[i, j] + squared_dist_means - 2*cross_ij
            else:
                a[j, i] = gencov_factor
                b[j, i] = 2*(cross_ij - squared_dist_means)/stat
                c[j, i] = c[j, i] + squared_dist_means - 2*cross_ij
    #Note at this point C has 0's on diagonal instead of nans

    this_A = gencov_factor*squared_prop_k2

    # compute coefficients involving i in cluster k1 and i' not in clusters
    # k1 or k2
    for i in k1_obs[0]:
        for j in other_obs:
            diff_ij = x[i,:] - x[j, :]
            cross_ij = sum(diff_ij * diff_means)

            if i > j:
                a[i, j] = this_A
                b[i, j] = 2*prop_k2*(cross_ij - prop_k2*squared_dist_means)/stat
                c[i, j] = c[i, j] + squared_prop_k2*squared_dist_means - 2*prop_k2*cross_ij
            else:
                a[j, i] = this_A
                b[j, i] = 2*prop_k2*(cross_ij - prop_k2*squared_dist_means)/stat
                c[j, i] = c[j, i] + squared_prop_k2*squared_dist_means - 2*prop_k2*cross_ij

    this_A = gencov_factor * squared_prop_k1

    # compute coefficients involving i in cluster k2 and i' not in clusters
    # k1 or k2
    for i in k2_obs[0]:
        for j in other_obs:
            diff_ij = x[i, :] - x[j, :]
            cross_ij = sum(diff_ij * diff_means)

            if i > j:
                a[i, j] = this_A
                b[i, j] = 2*prop_k1*(cross_ij - prop_k1*squared_dist_means)/stat
                c[i, j] = c[i, j] + squared_prop_k1*squared_dist_means - 2*prop_k1*cross_ij
            else:
                a[j, i] = this_A
                b[j, i] = 2*prop_k1*(cross_ij - prop_k1*squared_dist_means)/stat
                c[j, i] = c[j, i] + squared_prop_k1*squared_dist_means - 2*prop_k1*cross_ij

    # solve the inequalities
    for i in k1_obs[0]:
        hm1 = height_merge[i]
        for j in k2_obs[0]:
            hm2 = height_merge[j]
            if hm1 < hm2:
                upper_ij = hm1
            else:
                upper_ij = hm2

            current_height = heights[upper_ij]

            if i > j:
                new_intervals = solve_one_ineq(gencov_factor, b[i, j], c[i,j] \
                                - current_height)
            else:
                new_intervals = solve_one_ineq(gencov_factor, b[j, i], c[j,i] \
                                               - current_height)


def compute_s_mcquitty_gencov(x, hcl, k, k1, k2, stat):
    pass

def compute_s_median_gencov(x, hcl, k, k1, k2, stat):
    pass